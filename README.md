#Comment Intelligence (TikTok)

A small full-stack project that scrapes TikTok comments, cleans them (Indonesian-aware), runs sentiment + topic modeling, and lets you query with Hybrid RAG (BM25 + pgvector) â€” all with a FastAPI backend and a Streamlit UI.

Stack: FastAPI Â· Streamlit Â· PostgreSQL + pgvector Â· LangChain Â· BERTopic Â· SentenceTransformers
Flow: Scrape TikTok â†’ Preprocess (ID) â†’ Sentiment â†’ Topic Modeling â†’ Hybrid RAG â†’ Save to DB & Files

##âœ¨ Screenshots

Replace these placeholders with your own screenshots.

Pipeline Analysis Page	RAG Query Page

	
##ğŸš€ Features

TikTok Scraper (Apify): Pulls comments by video URL

Indonesian Text Preprocessing: removes URLs, mentions, emojis, slang, etc.

Sentiment Analysis (IndoBERT): positive / neutral / negative + confidence

Topic Modeling (BERTopic): topic labels using SentenceTransformers embeddings

Hybrid RAG: BM25 (lexical) + pgvector (semantic), optional LLM (Qwen) to draft answers

Persistence: saves analysis to PostgreSQL and artifacts to CSV/JSON/TXT

CPU-friendly by default: works fine without a GPU

##ğŸ§± Tech Stack

Backend: FastAPI

Frontend: Streamlit

Database: PostgreSQL 14+ with pgvector

Orchestration & LLM: LangChain

Models: BERTopic, SentenceTransformers, IndoBERT

Deployment: Docker & Docker Compose

##ğŸ“‹ Prerequisites

Option A (recommended): Docker & Docker Compose

Option B (local): Python 3.11+, PostgreSQL 14+ with pgvector extension enabled

API keys:

APIFY_API_TOKEN (required) â€“ to scrape TikTok comments

QWEN_API_KEY (optional) â€“ to generate RAG answers with Qwen (OpenAI-compatible)

##âš™ï¸ Setup
1) Environment Variables

Copy the example and fill it:

cp .env.example .env


###.env example

# ==== Backend ====
LOG_LEVEL=INFO
DATA_DIR=/app/data
# "" (no suffix), AUTO (timestamp), or your custom label:
SAVE_TS_SUFFIX=AUTO

# TikTok scraping
APIFY_API_TOKEN=apify_xxxxxxxxxxxxxxxxxxxxxxx

# Postgres/pgvector (service name follows docker-compose)
PGVECTOR_URL=postgresql://user:pass@doc_pgvector:5432/appdb
PGVECTOR_COLLECTION=comments

# Qwen (optional, OpenAI-compatible)
QWEN_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxx
QWEN_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1

# ==== Frontend ====
BACKEND_URL=http://backend:8000


##âš ï¸ Security: Donâ€™t commit .env to public repos.

2) Run with Docker (Recommended)
docker compose up -d --build


Access:

Backend (Swagger UI): http://localhost:8000/docs

Frontend (Streamlit): http://localhost:8601

Tail logs:

docker compose logs -f backend
docker compose logs -f frontend
docker compose logs -f db


Rebuild a stale backend:

docker compose build --no-cache backend
docker compose up -d --force-recreate backend

3) Run Locally (No Docker)

Make sure PostgreSQL is running and pgvector is enabled:

CREATE EXTENSION IF NOT EXISTS vector;


Create venv & install deps:

python -m venv .venv
# Windows: .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt


Export the same variables from .env.

Start backend:

uvicorn backend.api.main:app --host 0.0.0.0 --port 8000 --reload


Start frontend (another terminal):

streamlit run frontend/Home.py --server.port 8601

##ğŸ—‚ï¸ Project Structure
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/main.py               # FastAPI routes
â”‚   â”œâ”€â”€ graph/pipeline.py         # Orchestrates: scrape â†’ preprocess â†’ sentiment â†’ topic â†’ persist
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ scraper.py            # Apify TikTok scraper
â”‚   â”‚   â”œâ”€â”€ preprocessing.py      # IndonesianPreprocessor
â”‚   â”‚   â”œâ”€â”€ sentiment.py          # IndoBERT sentiment
â”‚   â”‚   â”œâ”€â”€ topic.py              # BERTopic + SentenceTransformer
â”‚   â”‚   â”œâ”€â”€ rag.py                # Hybrid RAG (BM25 + pgvector + optional Qwen)
â”‚   â”‚   â””â”€â”€ storage.py            # Save artifacts (CSV/JSON/TXT) to DATA_DIR
â”‚   â””â”€â”€ utils/db.py               # DB init + CRUD for comments/topics/vectors
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/Pipeline_Analisis.py # Run pipeline, view insight, download CSV/JSON/TXT
â”‚   â”œâ”€â”€ pages/rag.py               # RAG search & answer view
â”‚   â””â”€â”€ Home.py                    # Streamlit landing page
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

##ğŸ§­ How It Works (Data Flow)
flowchart LR
  A[Input TikTok URL] --> B[Scraper (Apify)]
  B --> C[Indonesian Preprocess]
  C --> D[Sentiment (IndoBERT)]
  D --> E[Topic Modeling (BERTopic)]
  E --> F[Persist â†’ Postgres + pgvector]
  F --> G[Artifacts CSV/JSON/TXT]
  F --> H[Hybrid RAG (BM25 + Vector)]
  H --> I[LLM Answer (Qwen, optional)]
  I --> J[Streamlit UI]

##ğŸ–¥ï¸ Using the App
1) Pipeline_Analisis Page

Open Pipeline_Analisis (sidebar).

Paste TikTok video URL, set a unique Content ID, Content Date, and Max Comments.

Click Run Pipeline.

Youâ€™ll see:

Insight Summary: dominant topics & sentiment distribution

Comments Table: text, sentiment, confidence, topic label, date

Downloads: JSON / CSV / TXT (insight)

2) RAG Page

Open RAG (sidebar).

Ask a question (e.g., â€œWhat do people think about product X?â€).

Youâ€™ll get:

Answer: summarized with Qwen (if QWEN_API_KEY set; otherwise just sources)

Sources: top comment snippets + metadata (topic, sentiment, hybrid score)

ğŸ”Œ API (FastAPI)
POST /analyze

Run the full pipeline (scrape â†’ analyze â†’ persist â†’ artifacts â†’ optional RAG).

Request

{
  "video_url": "https://www.tiktok.com/@user/video/123",
  "content_id": "indomie",
  "content_date": "2025-09-27",
  "max_comments": 50
}


Response (truncated)

{
  "insight": { "...": "..." },
  "merged_comments_count": 50,
  "merged_comments": [
    {
      "document_id": "indomie",
      "text": "...",
      "sentiment": "positive",
      "confidence": 0.98,
      "topic_label": "rasa - enak - pedas",
      "date": "2025-09-27"
    }
  ],
  "artifacts": {
    "json": "comments_indomie_20250928-011234.json",
    "csv": "comments_indomie_20250928-011234.csv",
    "insight_txt": "insight_indomie_20250928-011234.txt"
  },
  "rag": {
    "answer": "A summary answer from the LLM...",
    "sources": [{ "...": "..." }]
  }
}

POST /rag/query

Query the Hybrid RAG index.

Request

{
  "query": "What is the audience's main opinion about X?",
  "k": 3
}


Response (truncated)

{
  "answer": "Short answer with [1] [2] citations when relevant",
  "sources": [
    {
      "rank": 1,
      "snippet": "top context ...",
      "document_id": "indomie",
      "topic_label": "rasa - enak - pedas",
      "sentiment": "positive",
      "score_final": 0.75
    }
  ]
}

GET /files/{type}/{content_id}.{ext}

Download the latest analysis file.

Examples:

/files/comments/indomie.csv
/files/insight/indomie.txt

##ğŸ§ª Tips & Troubleshooting

RAG shows â€œ[No LLM]â€
You didnâ€™t set QWEN_API_KEY. Thatâ€™s okayâ€”search + sources still work.

AttributeError / stale code
Rebuild backend and clear caches:
docker compose build --no-cache backend && docker compose up -d --force-recreate backend

Apify returns 0 comments
Try another video, verify actor permissions, or increase max_comments.

404 when downloading files
Check that artifacts exist under DATA_DIR inside the backend container (/app/data by default).

pgvector not found
Ensure CREATE EXTENSION vector; on your Postgres.

Windows + Docker Desktop hiccups
If ports are busy, stop old containers or change host ports in docker-compose.yml.

##ğŸ§‘â€ğŸ’» Development Notes

Keep Streamlit expanders flat (avoid nested expanders).

Use CPU by default; no special CUDA setup required.

For long pipelines, prefer idempotent saves (timestamped filenames via SAVE_TS_SUFFIX=AUTO).

##ğŸ¤ Contributing

PRs welcome!
Keep docs friendly for first-timers, avoid huge diffs, and prefer small focused changes.

##ğŸ“œ License

MIT â€” see LICENSE.

##ğŸ™ Acknowledgements

Apify
 for scraping infra

pgvector
 for vector search in Postgres

BERTopic
 & SentenceTransformers

LangChain
 for orchestration helpers

Streamlit
 & FastAPI

Happy shipping! If you use this in the wild, drop a star â­ and share what you built.
