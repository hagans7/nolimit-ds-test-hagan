
# Comment Intelligence (TikTok)

A small full-stack project that scrapes TikTok comments, cleans them up, runs sentiment + topic modeling, and lets you query them with hybrid RAG (BM25 + pgvector) â€” all with a FastAPI backend and a Streamlit UI.

---

### TL;DR

-   **Stack**: FastAPI Â· Streamlit Â· PostgreSQL + pgvector Â· LangChain Â· BERTopic Â· SentenceTransformers
-   **What it does**: Scrape TikTok comments â†’ Preprocess (Indonesian) â†’ Sentiment Analysis â†’ Topic Modeling â†’ Hybrid RAG Search â†’ Persist to DB & Files.

---

## âœ¨ Screenshots

*(Replace these placeholders with your actual screenshots)*

| Pipeline Analysis Page                                                                  | RAG Query Page                                                                  |
| --------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------- |
| ![Pipeline Page](https://via.placeholder.com/400x300.png?text=Pipeline+Page) | ![RAG Page](https://via.placeholder.com/400x300.png?text=RAG+Query+Page) |

---

## ğŸš€ Key Features

-   **Scrape TikTok Comments**: Uses Apify to fetch comment data from TikTok videos.
-   **Text Preprocessing**: Tailored for Indonesian text (cleans URLs, mentions, slang, etc.).
-   **Sentiment Analysis**: Utilizes an `IndoBERT` model for sentiment classification (positive, negative, neutral).
-   **Topic Modeling**: Employs `BERTopic` to identify and label the main topics within the comments.
-   **Hybrid RAG Search**: Smart search combining BM25 (lexical search) and `pgvector` (semantic search), with answers generated by Qwen (optional).
-   **Data Persistence**: Saves analysis results as files (CSV, JSON, TXT) and persists them in a PostgreSQL database.

---

## ğŸ› ï¸ Tech Stack

-   **Backend**: FastAPI
-   **Frontend**: Streamlit
-   **Database**: PostgreSQL + pgvector
-   **Orchestration & LLM**: LangChain
-   **AI Models**: BERTopic, SentenceTransformers, IndoBERT
-   **Deployment**: Docker & Docker Compose

---

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following:

1.  **Docker & Docker Compose**: Highly recommended for easy setup.
2.  **(Alternative)** Python 3.11+, PostgreSQL 14+ with the `pgvector` extension installed.
3.  **API Keys**:
    -   `APIFY_API_TOKEN`: For scraping TikTok comments.
    -   `QWEN_API_KEY`: (Optional) For generating RAG answers with an LLM.

---

## âš™ï¸ Getting Started

### 1. Environment Configuration

First, copy the `.env.example` file to a new file named `.env`.

```bash
cp .env.example .env
```

Next, open the `.env` file and fill in your credentials.

```env
# ---- Backend ----
LOG_LEVEL=INFO
DATA_DIR=/app/data
# "" (no suffix), AUTO (timestamp), or a custom label:
SAVE_TS_SUFFIX=AUTO

# TikTok scraping
APIFY_API_TOKEN=apify_xxxxxxxxxxxxxxxxxxxxxxx

# Postgres/pgvector (matches docker-compose service names)
PGVECTOR_URL=postgresql://user:pass@doc_pgvector:5432/appdb
PGVECTOR_COLLECTION=comments

# Qwen (optional, OpenAI-compatible)
QWEN_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxx
QWEN_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1

# ---- Frontend ----
BACKEND_URL=http://backend:8000
```

âš ï¸ Important: Do not commit your `.env` file to public repositories.

### 2. Run with Docker (Recommended)

This is the easiest and most consistent method. Build and run the containers in detached mode:

```bash
docker compose up -d --build
```

Once the containers are running, access the application at:

- **Backend (FastAPI Swagger UI)**: http://localhost:8000/docs  
- **Frontend (Streamlit)**: http://localhost:8601

To view logs from each service:

```bash
docker compose logs -f backend
docker compose logs -f frontend
docker compose logs -f db
```

If you update the backend code and changes don't apply, rebuild the container:

```bash
docker compose build --no-cache backend
docker compose up -d --force-recreate backend
```

### 3. Run Locally (No Docker)

Use this method if you prefer not to use Docker. Make sure Postgres with the `pgvector` extension is already running.

Create and activate a virtual environment:

```bash
python -m venv .venv
# Windows: .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate
```

Install dependencies:

```bash
pip install -r requirements.txt
```

Export the environment variables from your `.env` file (manually or using `python-dotenv`).

Start the Backend (FastAPI):

```bash
uvicorn backend.api.main:app --host 0.0.0.0 --port 8000 --reload
```

Start the Frontend (Streamlit) in a separate terminal:

```bash
streamlit run frontend/Home.py --server.port 8601
```

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/main.py                # FastAPI routes
â”‚   â”œâ”€â”€ graph/pipeline.py          # LangGraph pipeline
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ scraper.py             # Apify TikTok scraper
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # IndonesianPreprocessor
â”‚   â”‚   â”œâ”€â”€ sentiment.py           # IndoBERT sentiment
â”‚   â”‚   â”œâ”€â”€ topic.py               # BERTopic + SentenceTransformer
â”‚   â”‚   â”œâ”€â”€ rag.py                 # Hybrid RAG implementation
â”‚   â”‚   â””â”€â”€ storage.py             # File saving logic
â”‚   â””â”€â”€ utils/db.py                # Database operations
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/Pipeline_Analisis.py # Page to run the pipeline
â”‚   â”œâ”€â”€ pages/rag.py               # Page for RAG queries
â”‚   â””â”€â”€ Home.py                    # Main Streamlit homepage
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ–¥ï¸ How to Use the Application

### ğŸ“„ Pipeline_Analisis Page

Navigate to the **Pipeline_Analisis** page from the sidebar.

Paste the TikTok URL, a unique **Content ID**, the **Content Date**, and the **Max Comments** to scrape.

Hit the **Run Pipeline** button.

The application will display:

- **Insight Summary**: Dominant topics and sentiment distribution.
- **Comments Table**: Per-comment analysis results.
- **Download Buttons**: To download the results as JSON or CSV.

### ğŸ“š RAG Page

Navigate to the **RAG** page from the sidebar.

Type your question in the input box (e.g., *"What do people think about product X?"*).

The application will return:

- **Answer**: A summarized answer from the LLM (if `QWEN_API_KEY` is configured).
- **Sources**: The most relevant comment snippets with their metadata.

---

## ğŸ”Œ API Endpoints

Here are the main endpoints available from the FastAPI backend.

### `POST /analyze`

Runs the full analysis pipeline.

**Request Body**:
```json
{
  "video_url": "https://www.tiktok.com/@user/video/123",
  "content_id": "indomie",
  "content_date": "2025-09-27",
  "max_comments": 50
}
```

**Response**:
```json
{
  "insight": { "...": "..." },
  "merged_comments_count": 50,
  "merged_comments": [
    {
      "document_id": "indomie",
      "text": "...",
      "sentiment": "positive",
      "confidence": 0.98,
      "topic_label": "rasa - enak - pedas",
      "date": "2025-09-27"
    }
  ],
  "artifacts": {
    "json": "comments_indomie_20250928-011234.json",
    "csv": "comments_indomie_20250928-011234.csv",
    "insight_txt": "insight_indomie_20250928-011234.txt"
  },
  "rag": {
    "answer": "A summary answer from the LLM...",
    "sources": [{ "...": "..." }]
  }
}
```

### `POST /rag/query`

Sends a query to the RAG system.

**Request Body**:
```json
{
  "query": "What is the audience's main opinion about X?",
  "k": 3
}
```

**Response**:
```json
{
  "answer": "Short answer with [1] [2] citations when relevant",
  "sources": [
    {
      "rank": 1,
      "snippet": "top context ...",
      "document_id": "indomie",
      "topic_label": "rasa - enak - pedas",
      "sentiment": "positive",
      "score_final": 0.75
    }
  ]
}
```

### `GET /files/{type}/{content_id}.{ext}`

Downloads the latest analysis file from the server.

Examples:
- `GET /files/comments/indomie.csv`
- `GET /files/insight/indomie.txt`

---

## ğŸ”§ Troubleshooting

- **RAG returns `[No LLM]`**: You didnâ€™t set `QWEN_API_KEY`. This is expected if you only want search functionality without LLM-generated answers.
- **`AttributeError` in the backend**: Your backend container is stale. Rebuild it using the commands in the "Run with Docker" section.
- **Streamlit error `"Expanders may not be nested"`**: Ensure the UI code does not place an expander element inside another one.
- **Apify returns 0 comments**: Try a different TikTok video, check your Apify actor permissions, or increase `max_comments`.
- **File download 404**: Confirm that the pipeline ran successfully and that the files exist in the `/app/data` directory within the backend container.

---

## ğŸ¤ Contributing

PRs are very welcome!

- Keep the docs friendly for first-time users.
- Avoid nested expanders in Streamlit.
- Small, focused changes are easiest to review.

---

## ğŸ“œ License

This project is licensed under the MIT License. See the `LICENSE` file for details.
